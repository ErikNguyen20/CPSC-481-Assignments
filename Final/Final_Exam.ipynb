{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3AJee8zQ_CxU",
        "UyeP-55EjfO2",
        "eesNiYlmn-Da",
        "yMdKz_Jn6d7v"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1. Maze Problem"
      ],
      "metadata": {
        "id": "3AJee8zQ_CxU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8JAM5HT8zK3"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "\n",
        "MAZE = [\n",
        "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0],\n",
        "    [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1],\n",
        "    [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
        "    [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
        "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "]\n",
        "\n",
        "class MazeProblem:\n",
        "  def __init__(self, maze):\n",
        "    self.maze = maze\n",
        "    self.adj_list = {}\n",
        "    self.generate_graph()\n",
        "\n",
        "  # Generates the adjacency list graph based on the maze grid\n",
        "  def generate_graph(self):\n",
        "    for i in range(len(self.maze)):\n",
        "      for j in range(len(self.maze[0])):\n",
        "        # Creates a label for the current cell position\n",
        "        current_position_label = (chr(i + 65), j+1)\n",
        "\n",
        "        # Defines an empty set if the position is not defined\n",
        "        if current_position_label not in self.adj_list:\n",
        "          self.adj_list[current_position_label] = []\n",
        "\n",
        "        # Get valid indices positions in the grid\n",
        "        positions = []\n",
        "        if i > 0:\n",
        "          positions.append((i-1, j))\n",
        "        if j > 0:\n",
        "          positions.append((i, j-1))\n",
        "        if i < len(self.maze) - 1:\n",
        "          positions.append((i+1, j))\n",
        "        if j < len(self.maze[0]) - 1:\n",
        "          positions.append((i, j+1))\n",
        "\n",
        "        # Iterates over the possible directions\n",
        "        for adj_i, adj_j in positions:\n",
        "          # Checks if this is a wall\n",
        "          if self.maze[adj_i][adj_j] == 1:\n",
        "            continue\n",
        "          # Otherwise add it as a neighbor to the current position label\n",
        "          self.adj_list[current_position_label].append((chr(adj_i + 65), adj_j+1))\n",
        "\n",
        "  # Retrieves the entry or index of a node from within the priority queue.\n",
        "  # If it does not exist, return None\n",
        "  def _get_entry_in_p_queue(self, p_queue, node):\n",
        "    index = 0\n",
        "    for entry in p_queue:\n",
        "      if entry[2] == node:\n",
        "        return (entry, index)\n",
        "      index += 1\n",
        "    return None\n",
        "\n",
        "  # Given the index of an entry in the priority queue, delete it, and then add a new_entry\n",
        "  def _replace_entry_in_p_queue(self, p_queue, index: int, new_entry):\n",
        "    p_queue.pop(index)\n",
        "    heapq.heapify(p_queue)\n",
        "    heapq.heappush(p_queue, new_entry)\n",
        "\n",
        "  # Defines the heuristic used in the A star search (Manhattan distance)\n",
        "  def _heuristic_(self, from_node: tuple, to_node: tuple):\n",
        "    x = abs((ord(from_node[0]) - 65) - (ord(to_node[0]) - 65))\n",
        "    y = abs(from_node[1] - to_node[1])\n",
        "    return x + y\n",
        "\n",
        "\n",
        "  def A_star_search(self, start_node: tuple, target_node: tuple):\n",
        "    # Initialize open set (priority queue) and visited set.\n",
        "    p_queue = []\n",
        "    visited = set()\n",
        "    # Pushes the starting node to the heap\n",
        "    # The entry tuple is defined as: Heuristic + pathcost, pathcost, current_node, path\n",
        "    heapq.heappush(p_queue, [self._heuristic_(start_node, target_node), 0, start_node, [start_node]])\n",
        "\n",
        "    while len(p_queue) > 0:\n",
        "      # Retrieve the lowest cost entry\n",
        "      current_cost, path_cost, current_node, current_path = heapq.heappop(p_queue)\n",
        "\n",
        "      # Check if the current node is the target\n",
        "      if current_node == target_node:\n",
        "        return path_cost, current_path\n",
        "\n",
        "      # Add current node to visited set\n",
        "      visited.add(current_node)\n",
        "\n",
        "      for neighbor_node in self.adj_list[current_node]:\n",
        "        # Creates new path in memory and new entry that can be added to priority queue\n",
        "        new_path = current_path.copy()\n",
        "        new_path.append(neighbor_node)\n",
        "        new_entry = [path_cost + 1 + self._heuristic_(neighbor_node, target_node), path_cost+1, neighbor_node, new_path]\n",
        "\n",
        "        possible_p_queue_entry = self._get_entry_in_p_queue(p_queue, neighbor_node)\n",
        "        if possible_p_queue_entry is None and neighbor_node not in visited:\n",
        "          # Add this new path to the priority queue\n",
        "          heapq.heappush(p_queue, new_entry)\n",
        "        elif possible_p_queue_entry is not None and possible_p_queue_entry[0][0] > new_entry[0]:\n",
        "          # Replace existing priority queue node with this updated, better path\n",
        "          self._replace_entry_in_p_queue(p_queue, possible_p_queue_entry[1], new_entry)\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiates the MazeProblem class that contains the algorithm\n",
        "problem_1 = MazeProblem(MAZE)\n",
        "\n",
        "# 1) Reach goal 1 from starting point\n",
        "result = problem_1.A_star_search(('K', 6), ('A', 6))\n",
        "print(\"Part 1: From ('K', 6) to ('A', 6)\")\n",
        "print(\"Path: \", result[1])\n",
        "print(\"Tiles Traversed: \", result[0])\n",
        "\n",
        "# 2) Reach goal 2 from starting point\n",
        "result = problem_1.A_star_search(('K', 6), ('E', 3))\n",
        "print(\"\\nPart 2: From ('K', 6) to ('E', 3)\")\n",
        "print(\"Path: \", result[1])\n",
        "print(\"Tiles Traversed: \", result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF99aa66gPmH",
        "outputId": "c9109a89-1298-4fc0-d7cf-ee3fc7b78453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part 1: From ('K', 6) to ('A', 6)\n",
            "Path:  [('K', 6), ('K', 7), ('K', 8), ('K', 9), ('J', 9), ('I', 9), ('I', 8), ('I', 7), ('H', 7), ('G', 7), ('G', 8), ('G', 9), ('F', 9), ('F', 10), ('F', 11), ('E', 11), ('D', 11), ('C', 11), ('B', 11), ('A', 11), ('A', 10), ('A', 9), ('A', 8), ('A', 7), ('A', 6)]\n",
            "Tiles Traversed:  24\n",
            "\n",
            "Part 2: From ('K', 6) to ('E', 3)\n",
            "Path:  [('K', 6), ('K', 5), ('J', 5), ('I', 5), ('I', 4), ('I', 3), ('J', 3), ('K', 3), ('K', 2), ('K', 1), ('J', 1), ('I', 1), ('H', 1), ('G', 1), ('G', 2), ('G', 3), ('F', 3), ('E', 3)]\n",
            "Tiles Traversed:  17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2. States of the TicTacToe Board"
      ],
      "metadata": {
        "id": "UyeP-55EjfO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class TicTacToeProblem:\n",
        "  def __init__(self):\n",
        "    self.adj_list = {}\n",
        "\n",
        "  # Generates all of the tic tac toe states\n",
        "  def Generate(self, starting_state = 'X'):\n",
        "    print(\"Generating States...\")\n",
        "    self._generate_states_(\"---------\", starting_state)\n",
        "    print(f\"Done! Generated {len(self.adj_list)} states\")\n",
        "\n",
        "  def __check_leaf_state(self, current: str):\n",
        "    win_indices = [\n",
        "        [0, 1, 2], [3, 4, 5], [6,7, 8],\n",
        "        [0, 3, 6], [1, 4, 7], [2, 5, 8],\n",
        "        [0, 4, 8], [2, 4, 6]\n",
        "    ]\n",
        "    # Check if any of the players has won, thus no more states are valid after this point.\n",
        "    for position in win_indices:\n",
        "      if all(current[i] == 'O' for i in position) or all(current[i] == 'X' for i in position):\n",
        "        return True\n",
        "\n",
        "    # Checks if there are no more moves allowed.\n",
        "    if all(tile != '-' for tile in current):\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  # Generates the states using DFS\n",
        "  def _generate_states_(self, current: str, move: str):\n",
        "    # Base Case\n",
        "    if self.__check_leaf_state(current):\n",
        "      # Creates a leaf node in the adj_list\n",
        "      self.adj_list[current] = set()\n",
        "      return\n",
        "\n",
        "    if current not in self.adj_list:\n",
        "        self.adj_list[current] = set()\n",
        "    moveComplement = 'X' if move == 'O' else 'O'\n",
        "\n",
        "    # Iterates over next valid states\n",
        "    for i in range(len(current)):\n",
        "      if current[i] != '-':\n",
        "        continue\n",
        "      new_node = current[:i] + move + current[i+1:]\n",
        "\n",
        "      # Adds the node adjacency to the adj_list\n",
        "      self.adj_list[current].add(new_node)\n",
        "\n",
        "      # Recursively generate states for the adjacent states\n",
        "      self._generate_states_(new_node, moveComplement)\n",
        "\n",
        "  def export_json(self, path = \"states.json\"):\n",
        "    # Grabs the adjacency lists\n",
        "    data = {key: list(values) for key, values in self.adj_list.items()}\n",
        "\n",
        "    # Write the dictionary to a JSON file\n",
        "    with open(path, \"w\") as json_file:\n",
        "      json.dump(data, json_file, indent=4)\n",
        "      print(f\"Exported states to '{path}'.\")\n",
        "\n",
        "  def import_json(self, path = \"states.json\"):\n",
        "    # Read the JSON data from the file\n",
        "    with open(path, \"r\") as json_file:\n",
        "      data = json.load(json_file)\n",
        "\n",
        "    # Sets the adjacency lists\n",
        "    self.adj_list = {key: set(values) for key, values in data.items()}\n",
        "    print(f\"Imported states from '{path}'.\")\n"
      ],
      "metadata": {
        "id": "WfGZBs6PjlJy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiates the TicTacToeProblem class that contains the state space generation\n",
        "problem_2 = TicTacToeProblem()\n",
        "\n",
        "# Generates with X going first.\n",
        "%time problem_2.Generate('X')\n",
        "\n",
        "# Outputs as json file\n",
        "problem_2.export_json(\"game_states.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mocNxpbGm40N",
        "outputId": "9677690f-c841-4584-f03e-87c214cc27ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating States...\n",
            "Done! Generated 5478 states\n",
            "CPU times: user 4.22 s, sys: 17.3 ms, total: 4.24 s\n",
            "Wall time: 4.69 s\n",
            "Exported states to 'game_states.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3. MNIST Digit Classification"
      ],
      "metadata": {
        "id": "eesNiYlmn-Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "(X_train, Y_train),(X_test, Y_test)=tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the grayscale pixel values to 0-1\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPGlns4ym-jP",
        "outputId": "1466f755-6d50-4bc2-971b-881e75ba6d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.InputLayer((28, 28)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NTiV63IrYM9",
        "outputId": "c9f89aab-7fc9-4ef6-9d8e-a029296df711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 567434 (2.16 MB)\n",
            "Trainable params: 567434 (2.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the model\n",
        "model.fit(X_train, Y_train, validation_split=0.2, batch_size=32, epochs=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7wbYxkArr0G",
        "outputId": "47fdc80f-c392-45b1-d444-98a28927cd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "1500/1500 [==============================] - 21s 13ms/step - loss: 0.2120 - sparse_categorical_accuracy: 0.9346 - val_loss: 0.1573 - val_sparse_categorical_accuracy: 0.9517\n",
            "Epoch 2/16\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9725 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9712\n",
            "Epoch 3/16\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1049 - val_sparse_categorical_accuracy: 0.9686\n",
            "Epoch 4/16\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9681\n",
            "Epoch 5/16\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 6/16\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9768\n",
            "Epoch 7/16\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0285 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.1073 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 8/16\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.1121 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 9/16\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0252 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9779\n",
            "Epoch 10/16\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9765\n",
            "Epoch 11/16\n",
            "1500/1500 [==============================] - 17s 11ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9788\n",
            "Epoch 12/16\n",
            "1500/1500 [==============================] - 17s 12ms/step - loss: 0.0181 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0973 - val_sparse_categorical_accuracy: 0.9785\n",
            "Epoch 13/16\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9783\n",
            "Epoch 14/16\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.1199 - val_sparse_categorical_accuracy: 0.9776\n",
            "Epoch 15/16\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.1320 - val_sparse_categorical_accuracy: 0.9778\n",
            "Epoch 16/16\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.1678 - val_sparse_categorical_accuracy: 0.9696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a52005acbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Evaluates the model\n",
        "Y_predict = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_predict)\n",
        "print(\"Training Set Confusion Matrix\")\n",
        "print(cm)\n",
        "print(\"Accuracy Report:\")\n",
        "print(classification_report(Y_test, Y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc5sz-zVsLHP",
        "outputId": "bff64f2d-281d-4654-91cb-b92cecc4383c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n",
            "Training Set Confusion Matrix\n",
            "[[ 969    0    1    1    0    2    3    2    2    0]\n",
            " [   0 1119    1    3    0    1    2    4    5    0]\n",
            " [   0    2  922   13    1    0    2   85    7    0]\n",
            " [   0    0    0  997    0    2    0    8    2    1]\n",
            " [   2    0    2    1  950    0    5    7    1   14]\n",
            " [   1    0    0   21    0  859    1    1    4    5]\n",
            " [   2    3    0    1    3    4  940    0    5    0]\n",
            " [   0    0    1    0    0    0    0 1022    1    4]\n",
            " [   1    0    3    7    1    7    0    8  943    4]\n",
            " [   2    2    0    5    4    1    0   18    5  972]]\n",
            "Accuracy Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.89      0.94      1032\n",
            "           3       0.95      0.99      0.97      1010\n",
            "           4       0.99      0.97      0.98       982\n",
            "           5       0.98      0.96      0.97       892\n",
            "           6       0.99      0.98      0.98       958\n",
            "           7       0.88      0.99      0.94      1028\n",
            "           8       0.97      0.97      0.97       974\n",
            "           9       0.97      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4. California Housing Prices"
      ],
      "metadata": {
        "id": "yMdKz_Jn6d7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# # Load the dataset\n",
        "df = pd.read_csv(\"cal_housing.data\", header=None)\n",
        "X = df.iloc[:, :-1].to_numpy()\n",
        "Y = df.iloc[:, -1].to_numpy()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Preprocess the dataset\n",
        "X_scaler = StandardScaler()\n",
        "X_train = X_scaler.fit_transform(X_train)\n",
        "X_test = X_scaler.transform(X_test)\n",
        "\n",
        "Y_scaler = StandardScaler()\n",
        "Y_train = Y_scaler.fit_transform(Y_train.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6v4celn6h9o",
        "outputId": "a674be10-ee47-4a07-d983-ea47dca45ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 8) (4128, 8) (16512,) (4128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.InputLayer(8))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KebVnM138b4U",
        "outputId": "34dee375-c38e-4481-996b-c2788087b291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_101 (Dense)           (None, 256)               2304      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45569 (178.00 KB)\n",
            "Trainable params: 45569 (178.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the model\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=16, restore_best_weights=True)\n",
        "model.fit(X_train, Y_train, validation_split=0.2, batch_size=32, epochs=200, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVrLBDo989HF",
        "outputId": "b983ea7e-35c1-4b95-e1ab-d2eb93c11916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "413/413 [==============================] - 3s 5ms/step - loss: 0.5145 - mse: 0.5145 - val_loss: 0.3413 - val_mse: 0.3413\n",
            "Epoch 2/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.3750 - mse: 0.3750 - val_loss: 0.3215 - val_mse: 0.3215\n",
            "Epoch 3/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.3411 - mse: 0.3411 - val_loss: 0.3135 - val_mse: 0.3135\n",
            "Epoch 4/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.3251 - mse: 0.3251 - val_loss: 0.3174 - val_mse: 0.3174\n",
            "Epoch 5/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.3108 - mse: 0.3108 - val_loss: 0.2860 - val_mse: 0.2860\n",
            "Epoch 6/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.3028 - mse: 0.3028 - val_loss: 0.2919 - val_mse: 0.2919\n",
            "Epoch 7/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2974 - mse: 0.2974 - val_loss: 0.2810 - val_mse: 0.2810\n",
            "Epoch 8/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2906 - mse: 0.2906 - val_loss: 0.2735 - val_mse: 0.2735\n",
            "Epoch 9/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2813 - mse: 0.2813 - val_loss: 0.2683 - val_mse: 0.2683\n",
            "Epoch 10/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2763 - mse: 0.2763 - val_loss: 0.2593 - val_mse: 0.2593\n",
            "Epoch 11/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2733 - mse: 0.2733 - val_loss: 0.2571 - val_mse: 0.2571\n",
            "Epoch 12/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2722 - mse: 0.2722 - val_loss: 0.2626 - val_mse: 0.2626\n",
            "Epoch 13/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2643 - mse: 0.2643 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 14/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2663 - mse: 0.2663 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 15/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2651 - mse: 0.2651 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 16/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2598 - mse: 0.2598 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 17/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2594 - mse: 0.2594 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 18/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2558 - mse: 0.2558 - val_loss: 0.2430 - val_mse: 0.2430\n",
            "Epoch 19/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2546 - mse: 0.2546 - val_loss: 0.2396 - val_mse: 0.2396\n",
            "Epoch 20/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2514 - mse: 0.2514 - val_loss: 0.2320 - val_mse: 0.2320\n",
            "Epoch 21/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2509 - mse: 0.2509 - val_loss: 0.2413 - val_mse: 0.2413\n",
            "Epoch 22/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2503 - mse: 0.2503 - val_loss: 0.2370 - val_mse: 0.2370\n",
            "Epoch 23/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2399 - val_mse: 0.2399\n",
            "Epoch 24/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2443 - mse: 0.2443 - val_loss: 0.2321 - val_mse: 0.2321\n",
            "Epoch 25/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2421 - mse: 0.2421 - val_loss: 0.2303 - val_mse: 0.2303\n",
            "Epoch 26/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2425 - mse: 0.2425 - val_loss: 0.2354 - val_mse: 0.2354\n",
            "Epoch 27/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2435 - mse: 0.2435 - val_loss: 0.2252 - val_mse: 0.2252\n",
            "Epoch 28/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 0.2245 - val_mse: 0.2245\n",
            "Epoch 29/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2415 - mse: 0.2415 - val_loss: 0.2236 - val_mse: 0.2236\n",
            "Epoch 30/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2272 - val_mse: 0.2272\n",
            "Epoch 31/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2247 - val_mse: 0.2247\n",
            "Epoch 32/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2340 - mse: 0.2340 - val_loss: 0.2335 - val_mse: 0.2335\n",
            "Epoch 33/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.2283 - val_mse: 0.2283\n",
            "Epoch 34/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2335 - mse: 0.2335 - val_loss: 0.2224 - val_mse: 0.2224\n",
            "Epoch 35/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2351 - mse: 0.2351 - val_loss: 0.2222 - val_mse: 0.2222\n",
            "Epoch 36/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 0.2157 - val_mse: 0.2157\n",
            "Epoch 37/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2336 - mse: 0.2336 - val_loss: 0.2254 - val_mse: 0.2254\n",
            "Epoch 38/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2353 - mse: 0.2353 - val_loss: 0.2171 - val_mse: 0.2171\n",
            "Epoch 39/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2293 - mse: 0.2293 - val_loss: 0.2174 - val_mse: 0.2174\n",
            "Epoch 40/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2309 - mse: 0.2309 - val_loss: 0.2197 - val_mse: 0.2197\n",
            "Epoch 41/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2337 - mse: 0.2337 - val_loss: 0.2268 - val_mse: 0.2268\n",
            "Epoch 42/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2306 - mse: 0.2306 - val_loss: 0.2200 - val_mse: 0.2200\n",
            "Epoch 43/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2285 - mse: 0.2285 - val_loss: 0.2223 - val_mse: 0.2223\n",
            "Epoch 44/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2303 - mse: 0.2303 - val_loss: 0.2145 - val_mse: 0.2145\n",
            "Epoch 45/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2292 - mse: 0.2292 - val_loss: 0.2164 - val_mse: 0.2164\n",
            "Epoch 46/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.2186 - val_mse: 0.2186\n",
            "Epoch 47/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2234 - mse: 0.2234 - val_loss: 0.2109 - val_mse: 0.2109\n",
            "Epoch 48/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2243 - mse: 0.2243 - val_loss: 0.2115 - val_mse: 0.2115\n",
            "Epoch 49/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.2173 - val_mse: 0.2173\n",
            "Epoch 50/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.2145 - val_mse: 0.2145\n",
            "Epoch 51/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2222 - mse: 0.2222 - val_loss: 0.2147 - val_mse: 0.2147\n",
            "Epoch 52/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.2126 - val_mse: 0.2126\n",
            "Epoch 53/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.2170 - val_mse: 0.2170\n",
            "Epoch 54/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.2090 - val_mse: 0.2090\n",
            "Epoch 55/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2234 - mse: 0.2234 - val_loss: 0.2182 - val_mse: 0.2182\n",
            "Epoch 56/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2226 - mse: 0.2226 - val_loss: 0.2143 - val_mse: 0.2143\n",
            "Epoch 57/200\n",
            "413/413 [==============================] - 3s 7ms/step - loss: 0.2246 - mse: 0.2246 - val_loss: 0.2156 - val_mse: 0.2156\n",
            "Epoch 58/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2227 - mse: 0.2227 - val_loss: 0.2126 - val_mse: 0.2126\n",
            "Epoch 59/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 0.2168 - val_mse: 0.2168\n",
            "Epoch 60/200\n",
            "413/413 [==============================] - 5s 11ms/step - loss: 0.2209 - mse: 0.2209 - val_loss: 0.2152 - val_mse: 0.2152\n",
            "Epoch 61/200\n",
            "413/413 [==============================] - 4s 9ms/step - loss: 0.2198 - mse: 0.2198 - val_loss: 0.2129 - val_mse: 0.2129\n",
            "Epoch 62/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2140 - val_mse: 0.2140\n",
            "Epoch 63/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.2101 - val_mse: 0.2101\n",
            "Epoch 64/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2210 - mse: 0.2210 - val_loss: 0.2145 - val_mse: 0.2145\n",
            "Epoch 65/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2080 - val_mse: 0.2080\n",
            "Epoch 66/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2208 - mse: 0.2208 - val_loss: 0.2101 - val_mse: 0.2101\n",
            "Epoch 67/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2181 - mse: 0.2181 - val_loss: 0.2067 - val_mse: 0.2067\n",
            "Epoch 68/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2184 - mse: 0.2184 - val_loss: 0.2086 - val_mse: 0.2086\n",
            "Epoch 69/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.2150 - val_mse: 0.2150\n",
            "Epoch 70/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2200 - mse: 0.2200 - val_loss: 0.2072 - val_mse: 0.2072\n",
            "Epoch 71/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2180 - mse: 0.2180 - val_loss: 0.2088 - val_mse: 0.2088\n",
            "Epoch 72/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2154 - val_mse: 0.2154\n",
            "Epoch 73/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2188 - mse: 0.2188 - val_loss: 0.2051 - val_mse: 0.2051\n",
            "Epoch 74/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2100 - val_mse: 0.2100\n",
            "Epoch 75/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2085 - val_mse: 0.2085\n",
            "Epoch 76/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2083 - val_mse: 0.2083\n",
            "Epoch 77/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2176 - mse: 0.2176 - val_loss: 0.2138 - val_mse: 0.2138\n",
            "Epoch 78/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2129 - val_mse: 0.2129\n",
            "Epoch 79/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2145 - val_mse: 0.2145\n",
            "Epoch 80/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2147 - val_mse: 0.2147\n",
            "Epoch 81/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2061 - val_mse: 0.2061\n",
            "Epoch 82/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2183 - val_mse: 0.2183\n",
            "Epoch 83/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2163 - val_mse: 0.2163\n",
            "Epoch 84/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2044 - val_mse: 0.2044\n",
            "Epoch 85/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2065 - val_mse: 0.2065\n",
            "Epoch 86/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2066 - val_mse: 0.2066\n",
            "Epoch 87/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2072 - val_mse: 0.2072\n",
            "Epoch 88/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2082 - mse: 0.2082 - val_loss: 0.2128 - val_mse: 0.2128\n",
            "Epoch 89/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2100 - val_mse: 0.2100\n",
            "Epoch 90/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2106 - val_mse: 0.2106\n",
            "Epoch 91/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2101 - val_mse: 0.2101\n",
            "Epoch 92/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2054 - val_mse: 0.2054\n",
            "Epoch 93/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2028 - val_mse: 0.2028\n",
            "Epoch 94/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2065 - mse: 0.2065 - val_loss: 0.2079 - val_mse: 0.2079\n",
            "Epoch 95/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2086 - mse: 0.2086 - val_loss: 0.2052 - val_mse: 0.2052\n",
            "Epoch 96/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2090 - mse: 0.2090 - val_loss: 0.2020 - val_mse: 0.2020\n",
            "Epoch 97/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2082 - mse: 0.2082 - val_loss: 0.2046 - val_mse: 0.2046\n",
            "Epoch 98/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2061 - mse: 0.2061 - val_loss: 0.2083 - val_mse: 0.2083\n",
            "Epoch 99/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2053 - mse: 0.2053 - val_loss: 0.2080 - val_mse: 0.2080\n",
            "Epoch 100/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 0.2079 - val_mse: 0.2079\n",
            "Epoch 101/200\n",
            "413/413 [==============================] - 3s 8ms/step - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2046 - val_mse: 0.2046\n",
            "Epoch 102/200\n",
            "413/413 [==============================] - 3s 7ms/step - loss: 0.2057 - mse: 0.2057 - val_loss: 0.2062 - val_mse: 0.2062\n",
            "Epoch 103/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2086 - mse: 0.2086 - val_loss: 0.2127 - val_mse: 0.2127\n",
            "Epoch 104/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 0.2106 - val_mse: 0.2106\n",
            "Epoch 105/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2075 - mse: 0.2075 - val_loss: 0.2059 - val_mse: 0.2059\n",
            "Epoch 106/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2062 - mse: 0.2062 - val_loss: 0.2069 - val_mse: 0.2069\n",
            "Epoch 107/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2079 - mse: 0.2079 - val_loss: 0.2084 - val_mse: 0.2084\n",
            "Epoch 108/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2067 - mse: 0.2067 - val_loss: 0.2113 - val_mse: 0.2113\n",
            "Epoch 109/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2041 - mse: 0.2041 - val_loss: 0.2015 - val_mse: 0.2015\n",
            "Epoch 110/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2033 - mse: 0.2033 - val_loss: 0.2010 - val_mse: 0.2010\n",
            "Epoch 111/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 0.2101 - val_mse: 0.2101\n",
            "Epoch 112/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2034 - val_mse: 0.2034\n",
            "Epoch 113/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2040 - mse: 0.2040 - val_loss: 0.2013 - val_mse: 0.2013\n",
            "Epoch 114/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2045 - mse: 0.2045 - val_loss: 0.2069 - val_mse: 0.2069\n",
            "Epoch 115/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2033 - mse: 0.2033 - val_loss: 0.2046 - val_mse: 0.2046\n",
            "Epoch 116/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2035 - mse: 0.2035 - val_loss: 0.2030 - val_mse: 0.2030\n",
            "Epoch 117/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2043 - mse: 0.2043 - val_loss: 0.2103 - val_mse: 0.2103\n",
            "Epoch 118/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2014 - mse: 0.2014 - val_loss: 0.2060 - val_mse: 0.2060\n",
            "Epoch 119/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2043 - mse: 0.2043 - val_loss: 0.2070 - val_mse: 0.2070\n",
            "Epoch 120/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2054 - mse: 0.2054 - val_loss: 0.2074 - val_mse: 0.2074\n",
            "Epoch 121/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2026 - mse: 0.2026 - val_loss: 0.2096 - val_mse: 0.2096\n",
            "Epoch 122/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2042 - mse: 0.2042 - val_loss: 0.2036 - val_mse: 0.2036\n",
            "Epoch 123/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2019 - mse: 0.2019 - val_loss: 0.1987 - val_mse: 0.1987\n",
            "Epoch 124/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2008 - mse: 0.2008 - val_loss: 0.2008 - val_mse: 0.2008\n",
            "Epoch 125/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2040 - mse: 0.2040 - val_loss: 0.2040 - val_mse: 0.2040\n",
            "Epoch 126/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2028 - mse: 0.2028 - val_loss: 0.2017 - val_mse: 0.2017\n",
            "Epoch 127/200\n",
            "413/413 [==============================] - 2s 6ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 0.2092 - val_mse: 0.2092\n",
            "Epoch 128/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2018 - mse: 0.2018 - val_loss: 0.2020 - val_mse: 0.2020\n",
            "Epoch 129/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2027 - mse: 0.2027 - val_loss: 0.2038 - val_mse: 0.2038\n",
            "Epoch 130/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.1994 - mse: 0.1994 - val_loss: 0.2085 - val_mse: 0.2085\n",
            "Epoch 131/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.1995 - mse: 0.1995 - val_loss: 0.2064 - val_mse: 0.2064\n",
            "Epoch 132/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2041 - mse: 0.2041 - val_loss: 0.2074 - val_mse: 0.2074\n",
            "Epoch 133/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2034 - mse: 0.2034 - val_loss: 0.2036 - val_mse: 0.2036\n",
            "Epoch 134/200\n",
            "413/413 [==============================] - 3s 6ms/step - loss: 0.1985 - mse: 0.1985 - val_loss: 0.2004 - val_mse: 0.2004\n",
            "Epoch 135/200\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.2019 - mse: 0.2019 - val_loss: 0.2071 - val_mse: 0.2071\n",
            "Epoch 136/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2017 - mse: 0.2017 - val_loss: 0.1998 - val_mse: 0.1998\n",
            "Epoch 137/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2004 - mse: 0.2004 - val_loss: 0.2013 - val_mse: 0.2013\n",
            "Epoch 138/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.2015 - mse: 0.2015 - val_loss: 0.2052 - val_mse: 0.2052\n",
            "Epoch 139/200\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.1987 - mse: 0.1987 - val_loss: 0.1997 - val_mse: 0.1997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a51e89ab4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "# Evaluate the model\n",
        "Y_pred = Y_scaler.inverse_transform(model.predict(X_test).reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"MSE: \", mean_squared_error(Y_test, Y_pred))\n",
        "print(\"MAE: \", mean_absolute_error(Y_test, Y_pred))\n",
        "print(\"MAPE: \", mean_absolute_percentage_error(Y_test, Y_pred))\n",
        "print(\"R2_score: \", r2_score(Y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DSgoDRH9gvZ",
        "outputId": "a171c75e-2683-4f83-aa39-442a59b759ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 0s 2ms/step\n",
            "MSE:  2641750938.5155864\n",
            "MAE:  34744.302734375\n",
            "MAPE:  0.20106786078966926\n",
            "R2_score:  0.7984025611559922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate percentage difference\n",
        "percentage_difference = np.abs((Y_pred - Y_test) / Y_test) * 100\n",
        "\n",
        "# Get predictions within +-15%\n",
        "within_threshold = np.count_nonzero(percentage_difference <= 15)\n",
        "print(within_threshold / Y_pred.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w6p8qA3-Rrj",
        "outputId": "83842c65-d3cb-4444-9199-fe080006596b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5363372093023255\n"
          ]
        }
      ]
    }
  ]
}